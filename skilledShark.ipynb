{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "import shap\n",
    "# from ydata_profiling import ProfileReport\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reproducibility:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b211a10ac5cb06b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3562cc1424ebc8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Understanding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c572c4be038d12"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "diet = pd.read_csv('diet.csv', low_memory=False)\n",
    "diet['Diet'] = diet['Diet'].astype('category')\n",
    "diet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a203101be6504ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Box Plot of Ages by Diet: Explore relationships between numerical variables (Age) using a pair plot.\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Diet', y='Age', data=diet, palette='pastel')\n",
    "plt.title('Box Plot of Ages by Diet')\n",
    "plt.xlabel('Diet')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3115e15b8065ed20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "requests = pd.read_csv('requests.csv', low_memory=False)\n",
    "requests['HighProtein'] = requests['HighProtein'].astype('category')\n",
    "requests['LowSugar'] = requests['LowSugar'].astype('category')\n",
    "requests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bb2dbf6d2c0fc3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Correlation Heatmap: Visualize the correlation between numerical variables.\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = requests[['Time', 'HighCalories', 'LowFat', 'HighFiber']]\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Heatmap for Request Variables')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89e49915d7fe069"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.csv', low_memory=False)\n",
    "reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd0b14270e60d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Scatter Plot of Rating vs Like:Investigate the relationship between ratings and likes using a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reviews['Rating'], reviews['Like'], alpha=0.5, color='green')\n",
    "plt.title('Scatter Plot of Rating vs Like')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Like')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14c32fccb919d63e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "recipes = pd.read_csv('recipes.csv', low_memory=False)\n",
    "recipes.rename(columns={\n",
    "    'Name': 'RecipeName'\n",
    "}, inplace=True)\n",
    "recipes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd22b260ae91da1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Histogram for Calories:Explore the distribution of calories in recipes using a histogram.\n",
    "custom_bins = np.arange(0, 5100, 200)  # Adjust the range and interval as needed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(recipes['Calories'], bins=custom_bins, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Calories in Recipes')\n",
    "plt.xlabel('Calories')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Set x-axis labels\n",
    "plt.xticks(custom_bins)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1684c39f77419a7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Bar Plot for Recipe Categories: Visualize the distribution of recipes across different categories using a bar plot.\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='RecipeCategory', y='CookTime', data=recipes, palette='Set2')\n",
    "plt.title('Box Plot of Cook Time by Recipe Category')\n",
    "plt.xlabel('Recipe Category')\n",
    "plt.ylabel('Cook Time')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e934334a4a507210"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_request_review = pd.merge(reviews,requests,on=['AuthorId','RecipeId'])\n",
    "merged_request_review"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2e6cf72d8652ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#eatmap for Correlation: Visualize the correlation between numerical variables.\n",
    "correlation_matrix = merged_request_review[['Rating', 'Like', 'Time', 'HighCalories', 'LowFat', 'HighFiber']].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Heatmap for Merged Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12684a8daf250102"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Joining using common attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9f899608c6f8d47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_recipes_req_review= pd.merge(merged_request_review,recipes,on=['RecipeId'],how='right')\n",
    "merged_recipes_req_review"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb968b7390002997"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "author_ID = 'AuthorId'\n",
    "merged_diet_all = pd.merge(diet, merged_recipes_req_review, on=author_ID)\n",
    "# merged_request_recipes = pd.merge(requests, recipes, on='RecipeId', how='left')\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49daee29ad9a6b88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute the missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67ef3cd2b0bb2848"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1 value missing in diet column. Filled with most occuring value.\n",
    "merged_diet_all['Diet'] = merged_diet_all['Diet'].fillna('Vegetarian')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7bc65da7602be7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#impute the values for all dietary preferences for all ages with the most frequent RecipeId for that age in that category\n",
    "helper_df = merged_diet_all.groupby(['Age', 'Diet'])['RecipeId'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "helper_df.columns = ['Age', 'Diet', 'Most Common Recipe']\n",
    "def impute_recipe(row):\n",
    "    if pd.isnull(row['RecipeId']):\n",
    "        return helper_df[(helper_df['Age'] == row['Age']) & (helper_df['Diet'] == row['Diet'])]['Most Common Recipe'].values[0]\n",
    "    else:\n",
    "        return row['RecipeId']\n",
    "merged_diet_all['RecipeId'] = merged_diet_all.apply(impute_recipe, axis=1)\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56bb590b3ee5cfc8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fill the rest of the missing values in the merged_diet_all by mapping them from requests.csv with RecipeId as key \n",
    "# Create mapping DataFrames from `requests`\n",
    "map_time = requests.set_index('RecipeId')['Time'].to_dict()\n",
    "map_calories = requests.set_index('RecipeId')['HighCalories'].to_dict()\n",
    "map_protein = requests.set_index('RecipeId')['HighProtein'].to_dict()\n",
    "map_fat = requests.set_index('RecipeId')['LowFat'].to_dict()\n",
    "map_sugar = requests.set_index('RecipeId')['LowSugar'].to_dict()\n",
    "map_fiber = requests.set_index('RecipeId')['HighFiber'].to_dict()\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['Time'] = merged_diet_all['RecipeId'].map(map_time)\n",
    "merged_diet_all['HighCalories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['HighProtein'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['LowFat'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['LowSugar'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['HighFiber'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6ff0b6af8d3e1b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "map_name = recipes.set_index('RecipeId')['RecipeName'].to_dict()\n",
    "map_cook_time = recipes.set_index('RecipeId')['CookTime'].to_dict()\n",
    "map_prep_time = recipes.set_index('RecipeId')['PrepTime'].to_dict()\n",
    "map_category = recipes.set_index('RecipeId')['RecipeCategory'].to_dict()\n",
    "map_quantities = recipes.set_index('RecipeId')['RecipeIngredientQuantities'].to_dict()\n",
    "map_parts = recipes.set_index('RecipeId')['RecipeIngredientParts'].to_dict()\n",
    "map_calories = recipes.set_index('RecipeId')['Calories'].to_dict()\n",
    "map_fat_content = recipes.set_index('RecipeId')['FatContent'].to_dict()\n",
    "map_saturated_content = recipes.set_index('RecipeId')['SaturatedFatContent'].to_dict()\n",
    "map_cholesterol = recipes.set_index('RecipeId')['CholesterolContent'].to_dict()\n",
    "map_sodium = recipes.set_index('RecipeId')['SodiumContent'].to_dict()\n",
    "map_carbohydrate = recipes.set_index('RecipeId')['CarbohydrateContent'].to_dict()\n",
    "map_fiber = recipes.set_index('RecipeId')['FiberContent'].to_dict()\n",
    "map_sugar = recipes.set_index('RecipeId')['SugarContent'].to_dict()\n",
    "map_protein = recipes.set_index('RecipeId')['ProteinContent'].to_dict()\n",
    "map_servings = recipes.set_index('RecipeId')['RecipeServings'].to_dict()\n",
    "map_yield = recipes.set_index('RecipeId')['RecipeYield'].to_dict()\n",
    "\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['RecipeName'] = merged_diet_all['RecipeId'].map(map_name)\n",
    "merged_diet_all['CookTime'] = merged_diet_all['RecipeId'].map(map_cook_time)\n",
    "merged_diet_all['PrepTime'] = merged_diet_all['RecipeId'].map(map_prep_time)\n",
    "merged_diet_all['RecipeCategory'] = merged_diet_all['RecipeId'].map(map_category)\n",
    "merged_diet_all['RecipeIngredientQuantities'] = merged_diet_all['RecipeId'].map(map_quantities)\n",
    "merged_diet_all['RecipeIngredientParts'] = merged_diet_all['RecipeId'].map(map_parts)\n",
    "merged_diet_all['Calories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['FatContent'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['SaturatedFatContent'] = merged_diet_all['RecipeId'].map(map_saturated_content)\n",
    "merged_diet_all['CholesterolContent'] = merged_diet_all['RecipeId'].map(map_cholesterol)\n",
    "merged_diet_all['SodiumContent'] = merged_diet_all['RecipeId'].map(map_sodium)\n",
    "merged_diet_all['CarbohydrateContent'] = merged_diet_all['RecipeId'].map(map_carbohydrate)\n",
    "merged_diet_all['FiberContent'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all['SugarContent'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['ProteinContent'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['RecipeServings'] = merged_diet_all['RecipeId'].map(map_servings)\n",
    "merged_diet_all['RecipeYield'] = merged_diet_all['RecipeId'].map(map_yield)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97229f12930cb918"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_diet_all['Rating'] = merged_diet_all['Rating'].fillna(0)\n",
    "merged_diet_all['TestSetId'] = merged_diet_all['TestSetId']\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c72759d12f3b5ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Balance the proportion of True and False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19907777292ad2e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df = merged_diet_all\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "proportion_true = df['Like'].mean()\n",
    "proportion_false = 1 - proportion_true\n",
    "\n",
    "# Identify the indices of false values\n",
    "false_indices = df[df['Like'] == False].index\n",
    "\n",
    "# Randomly sample false indices to achieve a balanced proportion\n",
    "num_false_to_sample = int(df['Like'].value_counts()[True] / proportion_true) - df['Like'].value_counts()[False]\n",
    "indices_to_sample = np.random.choice(false_indices, size=num_false_to_sample, replace=False)\n",
    "\n",
    "# Create a new DataFrame with sampled false values\n",
    "df_balanced = pd.concat([df[df['Like'] == True], df.loc[indices_to_sample]])\n",
    "\n",
    "# Shuffle the new DataFrame to randomize the order\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the proportion of true and false values in the balanced DataFrame\n",
    "print(df_balanced['Like'].value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a503f2efaf3093a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train a Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7effdf9c3873a9a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# 72.7 WITH 2000 ADD\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories','HighProtein','LowFat','LowSugar','HighFiber', 'CookTime', 'PrepTime','RecipeCategory', 'RecipeCategory', 'Calories', 'FatContent','SaturatedFatContent', 'CholesterolContent', 'SodiumContent',  'CarbohydrateContent','FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n",
    "\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,     # You can adjust this\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,    # You can adjust this\n",
    "    max_depth=3,          # You can adjust this\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,   # You can adjust this\n",
    "    subsample=1.0         # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cf788ae6509e47e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training a Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92dcda8ee998b6fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet','Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent',  'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'HighCalories', 'RecipeCategory', 'HighProtein']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Get all possible combinations of features\n",
    "\n",
    "\n",
    "best_combination = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over all feature combinations\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encodin\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model with hyperparameter tuning\n",
    "model_final_rfc = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=47,\n",
    "    max_depth=10,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt'\n",
    ")\n",
    "\n",
    "# Fit the model on the training set\n",
    "model_final_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_test_pred = model_final_rfc.predict(X_test)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the feature combination and its balanced accuracy\n",
    "# print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_test:.4f}\")\n",
    "\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d4216a322fe1d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Deploy the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5b7564d1ae0209"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "features = ['Diet','Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent',  'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'HighCalories', 'RecipeCategory', 'HighProtein','TestSetId','Like']\n",
    "df = merged_diet_all[features].copy()\n",
    "\n",
    "# Drop and save testsetid\n",
    "# Drop rows with NaN values in the target column ('Like') for training set\n",
    "predict_data = df[df['Like'].isna()]\n",
    "predict_data\n",
    "\n",
    "predict_data = predict_data.sort_values(by='TestSetId', ascending=True)\n",
    "predict_data\n",
    "# 1. One-Hot Encode Categorical Variables in predict_data\n",
    "predict_features = predict_data[features]  # 'features' list from your model training code\n",
    "predict_features_encoded = pd.get_dummies(predict_features)\n",
    "\n",
    "# 2. Align the Columns of predict_data with X_train\n",
    "# Add missing columns in predict_features_encoded with value equal to 0\n",
    "missing_cols = set(X_train.columns) - set(predict_features_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    predict_features_encoded[c] = 0\n",
    "\n",
    "# Ensure the order of columns in predict_features_encoded matches that of X_train\n",
    "predict_features_encoded = predict_features_encoded[X_train.columns]\n",
    "\n",
    "# 3. Make Predictions Using the Trained Model\n",
    "predicted_likes = model_final_rfc.predict(predict_features_encoded)\n",
    "\n",
    "# Combine Predictions with 'TestSetId'\n",
    "results_df = pd.DataFrame({\n",
    "    'id': predict_data['TestSetId'],\n",
    "    'prediction': predicted_likes\n",
    "})\n",
    "results_df['id'] = results_df['id'].astype(int)\n",
    "results_df['prediction'] = results_df['prediction'].replace({True: 1, False: 0})\n",
    "\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(results_df.head())\n",
    "results_df.to_csv('predictions_skilled_shark.csv',index=False)\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e39e96dc4ff794db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
